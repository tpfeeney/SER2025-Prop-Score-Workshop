---
title: "Propensity Score Workshop"
author: "Timothy Feeney, Catie Wiener, Tobias Kurth"
execute:
  echo: true
  eval: true
  output: true

format:
  revealjs:
    transition: slide
    background-transition: fade
    transition-speed: slow
    slide-number: true
    footer: "***SER 2025 Propensity Score Workshop, June 9th 2025***"

toc: true
toc-depth: 1
  
---

# Preliminaries

## Teaching Team Introductions

- Tobias Kurth, Charité, Berlin Germany
- Catie Weiner, UNC Chapel Hill, USA
- Timothy Feeney, UNC Chapel Hill, USA

## Outline of the workshop

1) Didactics
  - background and theory of basic propensity scores
  - estimands discussion
  - theory of inverse probability weighting
  - theory of standard error (SE) estimation
2) Practical Activities
  - Breakout sessions to practice and use what we are teaching
  - Will do propensity score analysis, boostrapping, m-estimation
  - Will use R for coding. RMarkdown Files have been provided for reference

## Schedule for the Afternoon
### First half

1:10-1:20 Introduction to Clinical Problem

1:20-1:40 First Activity:

  - Descriptive and Crude Analysis

1:40-2:40 Didactics:

  - Overview of causal, estimands, propensity score basics

2:40-3:10 Second Activity: 

  - Estimation of ATE and ATT using IPTW

3:10-3:30 Break

## Schedule for the Afternoon
### Second half

3:30-4:10 Didactics: 

  - Standard Error estimation using Bootstrapping 
  - Standard error estimation using M-estimation

4:10-4:50 Third Activity: 

  - Using Bootstrap and M-estimation

4:50-5:00 Questions and Closing Remarks

## Acknowledgments

This workshop uses information from the following resources


- HSPH EPI 271 course materials

- UNC CH BIOS 776 Causal Notes

- What If Casual Textbook by *Hernan and Robins*

- Manuscripts by Kurth *et al.* 2005, Wiener *et al* 2025 and Ross *et al.* 2023

- Essential Statistical Inference by *Stefanski and Boos*

## {.center}


**What do you want to get out of this course?**

::: {.notes}
We want to know what you want to get out of this course
:::

# Question of Interest and Background

## The Clinical Setup
![Two General Types Of Stroke](figures/stroke.jpeg)

## The Clinical Setup

  - Tissue plasminogen activatory (t-PA) can breakdown clots and has become a standard of care

  - Kurth *et al.* in 2005 found that the effect of TPA in an observational cohort depends on method of confounding control, and when standardized to the whole sample tPA was harmful.

  - PS distribution also suggested that there specific populations where there might be benefit

## Dataset

Westphalian Stroke Registry

- Stroke Registry of Northwestern Germany (Qualitätssicherung Schlaganfall Nordwestdeutschland, QSNWD)

- Data obtained from clinical records since 1999

- Contains information on: 

  - sociodemographis, cerebrovascular factors, comorbidites
  - details of hospital, admission modality
  - stroke type and severity, procedures, complications, and status at discharge

## FIRST ACTIVITY {.center}

### Descriptive Statistics

# What are we aiming to do here?

## The question of interest {.center}

What effect does tPA have on all cause mortality?

Is the effect the same in everyone? Is it the same in the whole population?

## Approaches to finding an answer

![](tables/research_types.png)

::: footer 
Hernán et al. (2019) A Second Chance to Get Causal Inference Right *Chance*
:::

## Learning about causes of effects

- if we gave a person tPA and observed their outcome 

- if instead we witheld tPA and observed the outcome

Would the outcomes be the same?

![](figures/rewind_time.png)

## Learning about causes of effects

- This is the idea behind counterfactuals

- If $A$ is treatment and $i$ indexes a person

- $Y$ is the observed outcome and

- $Y^{A=a}$ is the outcome had treatment $A=a$ 

- the comparisons of interest are $Y_i^{A=\text{tPA}}-Y_i^{A=\text{no tPA}}$  $\forall i$

- in words, would would the individual effect be had each patient $i$ recieved tPA versus not

## Learning about causes of effects

BUT

- we cannot learn about individual effects; 
    - we only have $Y_i^{A=\text{tPA}}$ OR $Y_i^{A=\text{no tPA}}$ for each $i$

- Thus we calculate $\textrm{E}\left[Y_i^{A=\text{tPA}}-Y_i^{A=\text{no tPA}}\right]$ 

- AKA the average treatment effect (ATE)

- The average effect had everyone gotten treatment, tPA, versus had everyone gotten no treatment, no tPA.

## Learning about causes of effects {.center}

:::: {.columns}
::: {.column width="60%"}
One approach is to use a time machine

::: {.fragment .fade-up}
But we know this is not feasible (currently)
:::

:::

::: {.column width="40%"}
![Tardis](figures/tardis.png)
:::
::::

## Estimating the Average Treatment Effect

Two ways to approach this:

|  | Benefits | Problems |
|---|:-----|:------|
| Randomized Trials    | Balanced groups in expectation   |   Perhaps infeasible, non generalizable | 
| Observational Studies     | Generalizable, potentially more feasible  |   Confounding, *et al* |

We will focus on Observational Studies here

## Causal Identification Conditions {auto-animate=true}

::: {style="margin-top: 100px;"}
Conditional Exchangeability: $Y^{(1)}, Y^{(0)}\perp\!\!\!\perp A| L$
:::

Consistency: $Y=Y^{a=1}A+Y^{a=0}(1-A)$

Positivity: $P[A=a|L]>0$ 

## A major concern of non-randomized studies {auto-animate=true}

::: {style="margin-top: 200px; font-size: 1em; color: red;"}
Conditional Exchangeability: $Y^{(1)}, Y^{(0)}\perp\!\!\!\perp A| L$
:::

## Confounders are a major concern

Confounder: On a causal path to the outcome AND on a causal path to the exposure AND not caused by the the outcome or exposure.

![](figures/confounder.png)


## Methods to control for confounding

- Matching

- Restriction

- Regression Modeling

- Weighting

::: {.fragment .fade-up}
These are all amenable to propensity methods
:::

::: {.fragment .fade-up}
We will focus on weighting
:::

## Propensity Score- Definition

The propensity score is the probability of being in a treatment group conditional on covariates--it is the propensity to be treated

$$P[A=a| \mathbf{L}]$$

where $A$ is treatment level and $\mathbf{L}$ is a vector of covariates.

We will denote propensity score as $\pi(\mathbf{L})$ for simplicity

## Propensity score- Exhangeability

The propensity score is a balancing score[^1]. If we have a set of $\mathbf{L}$ such that $\left(Y^{0},Y^{1}\right)\perp\!\!\!\perp A \mid \mathbf{L}$ then 
$$\left(Y^{0},Y^{1}\right)\perp\!\!\!\perp A \mid \pi \left(\mathbf{L}\right)$$

In other words, if $\mathbf{L}$ represents a vector that contains all variables necessary to achieve exchangeability then the propensity score can provide exchangeability.

How do we determine what should be in  $\mathbf{L}$?

[^1]: Rosenbaum and Rubin. *Biometrika* 1983

## Model building and variable selection

Like all causal analysis, variable selection should be principled, guided by your estimand, and driven by your DAG

1) Identify Variables in your DAG that you believe may be confounders.[^2]

2) Exclude variables that are 
  a) mediators of your effect of interest
  b) instruments of your exposure 

[^2]: Brookhart *et al.* Variable Selection for Propensity Score Models. *AJE* 2006

## DAG {auto-animate=true}

| Medical Hx | Sx and Signs | Demographics | Admission |
|-----------------|-----------------|-----------------|-----------------|
| Cardiac Illness Hx    | Paresis    | Age  | Transport Type |
| HTN                   | Aphasia| Gender   | Time To admission |
| AFib                  | Consciousness    | Admission Location   |
| Diabetes              | Rankin Scale   |  |

## DAG {auto-animate=true}

![](figures/daggity.png){.absolute width="800" left=150}

## DAG {auto-animate=true}

![](figures/dag.png)


## Propensity Score Estimation

Typically use logistic regression to estimate.

$\text{logit}\left[\widehat{\pi}\left(\mathbf{L}\right)\right]=\text{logit}\left(P\left[A=a \mid \mathbf{L}\right]\right)=\alpha_0+\boldsymbol{\alpha}^T\pi\left(\mathbf{L}\right)$

and

$\widehat{\pi}\left(\mathbf{L}\right)=\text{expit}\left[\text{logit}\left(P\left[A=a \mid \mathbf{L}\right]\right)\right]=\text{expit}\left[\alpha_0+\boldsymbol{\alpha}^T\pi\left(\mathbf{L}\right)\right]$

where $\text{logit}=\text{log}\left(\frac{P\left[A=a \mid \mathbf{L}\right]}{1-P\left[A=a \mid \mathbf{L}\right]}\right)$ and $\text{expit}=\left(\frac{1}{1+\exp^{\alpha_0+\boldsymbol{\alpha}^T\pi\left(\mathbf{L}\right)}} \right)$
in R 

```{.r}
#model the logit of being in treatment
model<-glm(A~L, data=df, family=binomial(link='logit'))

#predict the probability of being in treatment based on covariates
prop_score<-predict(model, type='response')
```


## Advantages

::::{.columns}

:::{.column width="40%"}

  - Collapses predictors of treatment into a single value.
    - avoid curse of dimensionality.[^1]

  - Relatively easy to estimate.

  - Multiple uses.
:::

:::{.column width="60%"}
![](figures/prop_score.png)
:::

::::
[^1]: Cepeda *et el.* Comparison of Logistic Regression versus Propensity Score When the Number of Events Is Low and There Are Multiple Confounders. *AJE*. 2003



## Disadvantages
	
  - Still rely on the assumption that you have all variables necessary to achieve exchangeability. 
  
    - **There is no magic here, this is not an RCT**

  - People with same propensity score may have different distribution of covariates.

  - Adds and extra step to estimation.

  - Estimation of standard error may be more complex.


## Propensity Score Diagnostics

::::{.columns}

:::{.column width="30%"}
-Distribution of scores

-Overlap

-Trimming?

-Truncation?
:::

:::{.column width="70%"}
![](/figures/score_dist.png)
:::
::::

::: aside
 Kurth *et al.* AJE 2006
:::

## Inverse Probability of Treatment Weights

- In Epidemiology we are often interested in marginal estimates of effect

- To achieve this we often use Inverse Probability of Treatment weights (IPTW)

$$\text{IPTW}=W_{IPTW}=\left(f(A\mid\mathbf{L})\right)^{-1}=\frac{1}{P[A\mid\mathbf{L}]}$$


## How IPTW works

![](/figures/datatable.png){.absolute width="200" left=0}

![](/figures/tree1.png){.absolute width="350" right=500 top=50}

![](/figures/tree2.png){.absolute width="500" right=5 bottom=0}

::: aside
Hernan and Robins. *What if* 2020
:::

## How IPTW works

::::{.columns}
:::{.column width="30%"}
**Before**
<div style="width: 70%; font-size: 0.8em;">
|       |$A=1$|$A=0$| |
|:-----|:---|:----|:---|
| $L=0$| 4    |4    ||
| $L=1$| 9    |3    ||
| Total| 13   |7    |20|
</div>
:::

::: {.column width="70%"}

:::
::::

![](figures/confounder.png){.absolute width=1000 right=50 bottom=5}


## How IPTW works

::::{.columns}
:::{.column width="30%"}
**Before**
<div style="width: 70%; font-size: 0.8em;">
|       |$A=1$|$A=0$| |
|:------|:------|:-----|:---|
| $L=0$| 4    |4    ||
| $L=1$| 9    |3    ||
| Total| 13   |7    |20|
</div>

:::

:::{.column width="20%"}

::::

::: {.column width="30%"}
**After**
<div style="width: 70%; font-size: 0.8em;">


|       |$A=1$|$A=0$| |
|:------|:-----|:---|:---|
| $L=0$| 8    |8    ||
| $L=1$| 12   |12    ||
| Total| 20   |20    |40|
</div>
:::
::::
![](figures/confounder_iptw.png){.absolute width=1000 right=50 bottom=5}

## Stabilized Versus Unstabilized

$$\widehat{\mathrm{W}}_{US,i}=\frac{1}{f(A|\mathbf{L})}=\frac{1}{P[A|\mathbf{L}]}$$

Unstabilized weights are scaled by the probability of treatment.

$$\widehat{\mathrm{W}}_{S,i}=\frac{f(A)}{f(A|)\mathbf{L}}=\frac{P[A]}{P[A|\mathbf{L}]}$$


## Stabilized Versus Unstabilized

![](/figures/tree2.png){.absolute width="530" left=0 top=150}

![](/figures/tree3.png){.absolute width="530" right=0 top=150}

::: aside
Hernan and Robins *What if* 2020
:::


## Example ATE estimation

What is the ATE of quitting smoking versus not on weight change between 1971 and 1982?

We can use the example data from Hernan and Robins

Treatment of interest: Quitting smoking (qsmk)
Confounders: Sex, Age, Race

```{r}
require(causaldata)
require(dplyr)
ex<-causaldata::nhefs %>% select(wt82_71, qsmk, age, race, sex) %>% head()
ex
```

## Example ATE, Horvitz Thompson Estimator

$$\frac{1}{n}\sum_i \hat{\mathrm{W}}_iY_iA_i-\frac{1}{n}\sum_i \hat{\mathrm{W}}_iY_i(1-A_i) $$


```{r}
require(dplyr)
nhefs<-causaldata::nhefs
# Model treatment
trt_model<-glm(qsmk ~ as.factor(sex) + as.factor(race) + age + I(age^2), data=nhefs, 
                  family=binomial())
# Estimate propensity score
nhefs$prop_score<-ifelse(nhefs$qsmk==1, predict(trt_model, type="response"),
 1-predict(trt_model, type="response"))
# Estimate unstabilized IPTW
nhefs$w<-1/nhefs$prop_score
```

```{r}
#| echo: FALSE
nhefs %>% select(wt82_71, qsmk, age, race, sex, prop_score, w) %>% head(n=4)
```
## Example ATE, Horvitz Thompson Estimator

$$\frac{1}{n}\sum_i \hat{\mathrm{W}}_iY_iA_i-\frac{1}{n}\sum_i \hat{\mathrm{W}}_iY_i(1-A_i) $$

```{r}
#| echo: FALSE
require(dplyr)
nhefs<-causaldata::nhefs
# Model treatment
trt_model<-glm(qsmk ~ as.factor(sex) + as.factor(race) + age + I(age^2), data=nhefs, 
                  family=binomial())
# Estimate propensity score
nhefs$prop_score<-ifelse(nhefs$qsmk==1, predict(trt_model, type="response"),
 1-predict(trt_model, type="response"))
# Estimate unstabilized IPTW
nhefs$w<-1/nhefs$prop_score
```

```{r}
nhefs$treat<-nhefs$w*nhefs$wt82_71*nhefs$qsmk
nhefs$untrt<-nhefs$w*nhefs$wt82_71*(1-nhefs$qsmk)
ate<-mean(nhefs$treat, na.rm=T)-mean(nhefs$untrt, na.rm=T)
ate
```

## Example ATE, Hajek Estimator

We may instead want to use regression using least squares

If instead of minimizing 

$$\sum_i \left[Y_i-(\alpha_0 + \alpha_1 A)\right]^2$$

we minimze $$\sum_i \widehat{\mathrm{W}}\left[Y_i-(\alpha_0 + \alpha_1 A)\right]^2$$

then we obtain the hajek estimator

$$\widehat{\alpha}_1=\frac{\sum_i \widehat{W}_i Y_i A_i}{\sum_i \widehat{W}_i A_i}-\frac{\sum_i \widehat{W}_i Y_i\left(1-A_i\right)}{\sum_i \widehat{W}_i\left(1-A_i\right)} $$


## Example ATE, Hajek Estimator

$$\frac{\sum_i \widehat{W}_i Y_i A_i}{\sum_i \widehat{W}_i A_i}-\frac{\sum_i \widehat{W}_i Y_i\left(1-A_i\right)}{\sum_i \widehat{W}_i\left(1-A_i\right)} $$

```{r}
#| echo: FALSE
require(dplyr)
nhefs<-causaldata::nhefs
# Model treatment
trt_model<-glm(qsmk ~ as.factor(sex) + as.factor(race) + age + I(age^2), data=nhefs, 
                  family=binomial())
# Estimate propensity score
nhefs$prop_score<-ifelse(nhefs$qsmk==1, predict(trt_model, type="response"),
 1-predict(trt_model, type="response"))
# Estimate unstabilized IPTW
nhefs$w<-1/nhefs$prop_score
nhefs$treat<-nhefs$w*nhefs$wt82_71*nhefs$qsmk
nhefs$untrt<-nhefs$w*nhefs$wt82_71*(1-nhefs$qsmk)
ate<-mean(nhefs$treat, na.rm=T)-mean(nhefs$untrt, na.rm=T)
```

```{r}
# weighting the regression model
Y_model<-lm(wt82_71~qsmk, weights=w, data=nhefs)
# regression based ATE
Y_model$coefficients[2]
# Horvitz Thompson ATE
ate
```


## Advantages of IPTW

- Can be used in many scenarios to obatin marginal estimates
  - Average Treatment Effect [^4] -We saw this
  - Average Treatment Effect among Treated (ATT) [^5] -next
  - Average Treatment Effect among Untreated (ATU) -next
  - Used in Survival Analysis [^6] -not covered today

- Uses all the data

  [^4]: Hernan *et al.* What if 2020
  [^5]: Sato and Matsuyama *Epidemiology* 2003
  [^6]: Cole and Hernan *Comp Meth and Prog in Biomed* 2004

## The question of interest {.center}

What effect does tPA have on all cause mortality?

::: {.fragment .fade-up}
Is the ATE what we are interested in?

Do we expect that everyone coming into an ED would benefit from tPA?
:::

::: {.fragment .fade-up}
What if were were interested in the effect of giving everyone treatment versus not *only* in the treated?
:::

::: {.fragment .fade-up}
What if were were interested in the effect of giving everyone treatment versus not *only* in the untreated?
:::

## ATT

Average Effect among those that were treated.

ATT also known as the Standardized Mortality Ratio (SMR)[^8]

[^]7: Sato and Matsuyama *Epidemiology* 2003

## Estimating IPTW for the ATT {auto-animate=true}

Under a slightly different set of identification conditions:

Consistency: $Y=Y^{a=1}A+Y^{a=0}(1-A)$



::: {style="margin-top: 100px;"}
Positivity: $P[A=a|\mathbf{L}]>0 \ \forall \ l$ where $f(l|A=1)>0$ 

Conditional Exchangeability: $Y^{(0)}\perp\!\!\!\perp A| L$
:::

## Estimating IPTW for the ATT {auto-animate=true}

::: {style="margin-top: 200px; font-size: 1em; color: red;"}
Positivity: $P[A=a|\mathbf{L}]>0 \ \forall \ l$ where $f(l|A=1)>0$ 


Conditional Exchangeability: $Y^{(0)}\perp\!\!\!\perp A| L$
:::

## Estimating IPTW for the ATT

New weights to make the untreated look like the treated, thereby standing in for them.

$$
\widehat{W}_i= 
\begin{cases}
    A=1,&    1 \\
    A=0,& \frac{\widehat{\pi}(\mathbf{L})}{1-\widehat{\pi}(\mathbf{L})}
\end{cases}
$$

```{.r code-line-numbers='7-8'}
require(dplyr)
nhefs<-causaldata::nhefs
# Model treatment
trt_model<-glm(qsmk ~ as.factor(sex) + as.factor(race) + age + I(age^2), data=nhefs, 
                  family=binomial())
# Estimate propensity score
nhefs$prop_score<-ifelse(nhefs$qsmk==1, 1,
 predict(trt_model, type="response")/(1-predict(trt_model, type="response")))
 nhefs$w_att<-1/nhefs$prop_score
```


```{r}
#| echo: FALSE
require(dplyr)
nhefs<-causaldata::nhefs
# Model treatment
trt_model<-glm(qsmk ~ as.factor(sex) + as.factor(race) + age + I(age^2), data=nhefs, 
                  family=binomial())
# Estimate propensity score
nhefs$prop_score<-ifelse(nhefs$qsmk==1, 1,
 predict(trt_model, type="response")/(1-predict(trt_model, type="response")))
 nhefs$w_att<-1/nhefs$prop_score
```

```{r}
#| echo: FALSE
# weighting the regression model
Y_model<-lm(wt82_71~qsmk, weights=w_att, data=nhefs)
# regression based ATT
att<-Y_model$coefficients[2]
paste0("The estimated ATT is: ", round(att,2))
```

## ATU

Average Effect among those that were untreated.

ATT also known as the Standardized Risk/Rate Ratio (SMR)[^8]

[^8]: Sato and Matsuyama *Epidemiology* 2003

## Estimating IPTW for the ATU {auto-animate=true}

Under a slightly different set of identification conditions:

Consistency: $Y=Y^{a=1}A+Y^{a=0}(1-A)$



::: {style="margin-top: 100px;"}
Positivity: $P[A=a|\mathbf{L}]>0 \ \forall \ l$ where $f(l|A=0)>0$ 

Conditional Exchangeability: $Y^{(1)}\perp\!\!\!\perp A| L$
:::

## Estimating IPTW for the ATT {auto-animate=true}

::: {style="margin-top: 200px; font-size: 1em; color: red;"}
Positivity: $P[A=a|\mathbf{L}]>0 \ \forall \ l$ where $f(l|A=0)>0$ 


Conditional Exchangeability: $Y^{(1)}\perp\!\!\!\perp A| L$
:::

## Estimating IPTW for the ATT

New weights to make the treated look like the untreated, thereby standing in for them.

$$
\widehat{W}_i= 
\begin{cases}
    A=1,&    \frac{1-\widehat{\pi}(\mathbf{L})}{\widehat{\pi}(\mathbf{L})} \\
    A=0,& 1
\end{cases}
$$

```{.r code-line-numbers='7-8'}
require(dplyr)
nhefs<-causaldata::nhefs
# Model treatment
trt_model<-glm(qsmk ~ as.factor(sex) + as.factor(race) + age + I(age^2), data=nhefs, 
                  family=binomial())
# Estimate propensity score
nhefs$prop_score<-ifelse(nhefs$qsmk==0, 1,
 (1-predict(trt_model, type="response"))/predict(trt_model, type="response"))
 nhefs$w_atu<-1/nhefs$prop_score
```


```{r}
#| echo: FALSE
require(dplyr)
nhefs<-causaldata::nhefs
# Model treatment
trt_model<-glm(qsmk ~ as.factor(sex) + as.factor(race) + age + I(age^2), data=nhefs, 
                  family=binomial())
# Estimate propensity score
nhefs$prop_score<-ifelse(nhefs$qsmk==0, 1,
 (1-predict(trt_model, type="response"))/predict(trt_model, type="response"))
 nhefs$w_atu<-1/nhefs$prop_score
```

```{r}
#| echo: FALSE
# weighting the regression model
Y_model<-lm(wt82_71~qsmk, weights=w_atu, data=nhefs)
# regression based ATT
atu<-Y_model$coefficients[2]
paste0("The estimated ATT is: ", round(atu,2))
```



## SECOND ACTIVITY {.center}

Estimate the ATE, ATT, and ATU using IPTW in the tPA data

1) Explain in words what each estimand means in this context, and which you think has meaning

2) Estimate the ATE, ATT, and ATU in the data.


## Standard Error Estimation-Bootstrapping

## Standard Error Estimation
### M-Estimation


<!-- Starts 1pm
1-1:10 intros and overview of course
1:10-1:20 Introduction to clinical problem and the data we are using; TK
-Can introduce our DAG here TK?
1:20-1:40: First Activity
	Reading in data
	Make a table 1 with data (we need to have table 1 to compare to)
	Crude /multivariable analysis (comparison estimates for crude and multivariable analysis)
1:40-2:40p: Didactic Material TK, TF
	Overview of causal
Talk ATE
	Overview of propensity scores
		Theory
		Advantages
		Disadvantages
		Model building and variable selection
			-Can use a DAG to guide
		Diagnostics
			-Weight means, SMDs, distributions
			-Solutions if deviations, trimming/truncation
			-code
			-model output
	Introduce and discuss the ATT
	Compare and contrast ATE
2:40-3:10p Second Activity: Estimation of the ATE and ATT using IPTW
3:10-3:30p: Break
3:30-4:10p Didactic Material TF
	How to make inference with these 
	Standard Error estimation with Bootstrap (how it works, positives and negatives)
	M-Estimation
4:10-4:50p Third Activity:
	We go through the ATE bootstrap and M-Estimation
	They modify the ATE bootstrap and M-Estimation for the ATT
	Simulation for coverage
4:50-5p Questions and Goodbyes -->
